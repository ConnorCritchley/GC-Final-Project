{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9752364b-78dd-434d-bb43-74513e001afd",
   "metadata": {},
   "source": [
    "# Grand Circus Final Project\n",
    "### Car Crash and Safety Data Comparisons/Evaluations\n",
    "\n",
    "This project aims to compare safety ratings from crash tests to actual data of fatal crashes. The use of fatal crash data is better suited for hard crashes where occupant life is and was in danger, providing more relevant data entries compared to fender benders or other minimal 'traffic incidents'. This analysis could be useful for car buyers, car manufactureres, government testers, and insurance companies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c1e353-3240-4956-9f06-80bf359f3a82",
   "metadata": {},
   "source": [
    "## Extraction\n",
    "To start the ETA process, data but be extracted and placed into usable structures. To do this, we will be importing the data from the api(s) and any other flat file sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1cbf99cb-0957-45e9-8c5b-25535059fba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import os.path\n",
    "import tqdm\n",
    "\n",
    "# Begin pulling make names and ID's for internal use\n",
    "# Definitions endpoint query\n",
    "make_url = \"https://crashviewer.nhtsa.dot.gov/CrashAPI/definitions/GetVariableAttributes?variable=make&caseYear=2021&format=json\"\n",
    "\n",
    "if os.path.isfile(\"./data/GetVariableAttributes_Make.json\"):\n",
    "     with open('./data/GetVariableAttributes_Make.json', 'r') as openfile:\n",
    "        data = json.load(openfile)\n",
    "else:\n",
    "    # Get response\n",
    "    response = requests.get(make_url)\n",
    "    # Turn response into json\n",
    "    data = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2bc83b33-c8d6-4b97-a54e-ca3a1623f667",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drill down json to list of dictionary\n",
    "results = data['Results'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6327ea98-3fd8-4326-8512-4e82f3d1fa3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MakeID</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>American Motors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2</td>\n",
       "      <td>Jeep / Kaiser-Jeep / Willys- Jeep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>AM General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6</td>\n",
       "      <td>Chrysler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7</td>\n",
       "      <td>Dodge</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    MakeID                               Name\n",
       "3        1                    American Motors\n",
       "38       2  Jeep / Kaiser-Jeep / Willys- Jeep\n",
       "2        3                         AM General\n",
       "13       6                           Chrysler\n",
       "18       7                              Dodge"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split data into lists\n",
    "id_list = []\n",
    "name_list = []\n",
    "for entry in results:\n",
    "    id_list.append(int(entry['ID']))\n",
    "    name_list.append(entry['TEXT'])\n",
    "\n",
    "# Make columns dictionary based on lists\n",
    "data = {'MakeID': id_list, 'Name': name_list}\n",
    "\n",
    "# Create df using dictionary\n",
    "manufacturer_df = pd.DataFrame(data)\n",
    "\n",
    "# Sort by Id instead of name\n",
    "manufacturer_df = manufacturer_df.sort_values(by=['MakeID'])\n",
    "manufacturer_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87967865-162f-46ae-bc63-2f654e945c37",
   "metadata": {},
   "source": [
    "## Only Taking Top 11 Best-Selling Makes\n",
    "Since the API contains data for all involved in crashes, such as the American Motors Ambassador made from 1952-1974, a fair portion of vehicles are not statistically relevant, or would be outwighed by more common vehicles. To prevent a weighting issing where more prevalent vehicles scew results to thinking more crashes are common, we will be using some of the most popular makes only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "baf1e6b5-74e3-4e5a-ac66-54fab27ecd78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MakeID</th>\n",
       "      <th>MakeName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2</td>\n",
       "      <td>Jeep / Kaiser-Jeep / Willys- Jeep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7</td>\n",
       "      <td>Dodge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>12</td>\n",
       "      <td>Ford</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20</td>\n",
       "      <td>Chevrolet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>23</td>\n",
       "      <td>GMC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>35</td>\n",
       "      <td>Nissan/Datsun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>37</td>\n",
       "      <td>Honda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>48</td>\n",
       "      <td>Subaru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>49</td>\n",
       "      <td>Toyota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>55</td>\n",
       "      <td>Hyundai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>63</td>\n",
       "      <td>KIA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    MakeID                           MakeName\n",
       "38       2  Jeep / Kaiser-Jeep / Willys- Jeep\n",
       "18       7                              Dodge\n",
       "23      12                               Ford\n",
       "12      20                          Chevrolet\n",
       "27      23                                GMC\n",
       "55      35                      Nissan/Datsun\n",
       "30      37                              Honda\n",
       "73      48                             Subaru\n",
       "76      49                             Toyota\n",
       "31      55                            Hyundai\n",
       "41      63                                KIA"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_keep = ['Nissan/Datsun', 'Toyota', 'KIA', 'Honda', 'Subaru', 'Ford', 'Chevrolet', 'Hyundai', 'Jeep / Kaiser-Jeep / Willys- Jeep', 'GMC', 'Dodge']\n",
    "new_df = manufacturer_df[manufacturer_df['Name'].isin(to_keep)]\n",
    "manufacturer_df = new_df\n",
    "manufacturer_df.rename(columns={'Name': 'MakeName'}, inplace=True)\n",
    "manufacturer_df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8171ec78-5dc6-492c-a643-8411b831d4b8",
   "metadata": {},
   "source": [
    "### Fetching Model IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f77afb5a-cb67-4eef-ada7-921085d3c8bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m make_ID \u001b[38;5;129;01min\u001b[39;00m manufacturer_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMakeID\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m      4\u001b[0m     model_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://crashviewer.nhtsa.dot.gov/CrashAPI/definitions/GetVariableAttributesForModel?variable=model&caseYear=2021&make=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmake_ID\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m&format=json\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 5\u001b[0m     response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(model_url)\n\u001b[1;32m      6\u001b[0m     model_data \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m      8\u001b[0m     results_model \u001b[38;5;241m=\u001b[39m model_data\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mResults\u001b[39m\u001b[38;5;124m'\u001b[39m) \n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, params\u001b[38;5;241m=\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[1;32m    668\u001b[0m         method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    669\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m    670\u001b[0m         body\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mbody,\n\u001b[1;32m    671\u001b[0m         headers\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    672\u001b[0m         redirect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    673\u001b[0m         assert_same_host\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    674\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    675\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    676\u001b[0m         retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries,\n\u001b[1;32m    677\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m    678\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[1;32m    679\u001b[0m     )\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/urllib3/connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    786\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[1;32m    790\u001b[0m     conn,\n\u001b[1;32m    791\u001b[0m     method,\n\u001b[1;32m    792\u001b[0m     url,\n\u001b[1;32m    793\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[1;32m    794\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[1;32m    795\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m    796\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[1;32m    797\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[1;32m    798\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[1;32m    799\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[1;32m    800\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[1;32m    802\u001b[0m )\n\u001b[1;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    805\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/urllib3/connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/urllib3/connection.py:507\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[1;32m    506\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 507\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/http/client.py:1423\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1421\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1422\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1423\u001b[0m         response\u001b[38;5;241m.\u001b[39mbegin()\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1425\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/http/client.py:331\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 331\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_status()\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    333\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/http/client.py:292\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 292\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    294\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/socket.py:707\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 707\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[1;32m    708\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    709\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/ssl.py:1252\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1250\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1251\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(nbytes, buffer)\n\u001b[1;32m   1253\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/ssl.py:1104\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1102\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1104\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1105\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1106\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "all_models = []\n",
    "for make_ID in manufacturer_df['MakeID']:\n",
    "    model_url = f'https://crashviewer.nhtsa.dot.gov/CrashAPI/definitions/GetVariableAttributesForModel?variable=model&caseYear=2021&make={make_ID}&format=json'\n",
    "    response = requests.get(model_url)\n",
    "    model_data = response.json()\n",
    "    \n",
    "    results_model = model_data.get('Results') \n",
    "\n",
    "    time.sleep(1)\n",
    "    for model in results_model:\n",
    "        all_models.append({\n",
    "            'MakeID': make_ID,\n",
    "            'Models': model[0:]\n",
    "        })\n",
    "# Drill down into JSON\n",
    "drill_down = all_models[0]['Models']\n",
    "drill_down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f975846-4c4f-402c-9e31-2bb99fedbfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_df = pd.DataFrame(all_models).sort_values(by='MakeID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296eff43-371d-498c-8135-b035e2aadc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge manufacturer_df & models_df\n",
    "merged_df = pd.merge(manufacturer_df, models_df, on=\"MakeID\", how=\"left\")\n",
    "merged_df = merged_df.sort_values(by='MakeID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a6bdb8-c6af-4eb7-aae7-690453516390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode the Models column to separate rows\n",
    "exploded_df = merged_df.explode('Models')\n",
    "exploded_df.reset_index(inplace=True)\n",
    "exploded_df.drop('index', axis=1, inplace=True) \n",
    "exploded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fe24db-09e0-476f-b335-46dc31bf37b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract ID and MODELNAME from the dictionaries in the Models column\n",
    "exploded_df['ModelID'] = exploded_df['Models'].apply(lambda x: x['ID'] if isinstance(x, dict) else None)\n",
    "exploded_df['ModelName'] = exploded_df['Models'].apply(lambda x: x['MODELNAME'] if isinstance(x, dict) else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf8e488-2222-455c-b971-e511e13a31b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the original Models column\n",
    "df = exploded_df.drop(columns=['Models'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd0f76b-8e8c-4a34-a9a0-1ce2d2d27692",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c39fc4-48ac-49f0-8e01-838174e86671",
   "metadata": {},
   "source": [
    "## Bodytype fetching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d45048b-b386-4473-b7b5-0287a847c22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Every car needs a body type to query the api with\n",
    "base_url = \"https://crashviewer.nhtsa.dot.gov/CrashAPI/definitions/GetVariableAttributesForbodyType\"\n",
    "\n",
    "bodytypes = []\n",
    "\n",
    "# loop through every row in dataframe\n",
    "for car in tqdm.tqdm(range(len(df))):\n",
    "    if os.path.isfile(\"body-types.json\"):\n",
    "        break\n",
    "    # for every car in dataframe     df.iloc[0]['A']\n",
    "    params = f\"?variable=bodytype&make={df.iloc[car]['MakeID']}&model={df.iloc[car]['ModelID']}&format=json\"\n",
    "    # get \"BODY_ID\" from responses and append to each row\n",
    "    # Get response\n",
    "    response = requests.get(base_url + params)\n",
    "\n",
    "    # check if successful\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Error: Received status code {response.status_code}\")\n",
    "        print(f\"Response content: {response.text}\")\n",
    "        raise Exception(f\"API request failed with status code {response.status_code}\")\n",
    "    # Turn response into json\n",
    "    data = response.json()\n",
    "\n",
    "    # drill down\n",
    "    results = data['Results'][0]\n",
    "\n",
    "    # pull data from each bodytype per car\n",
    "    # format is going to be a list of dictionaries, such that the bodytypes list will be like bodytypes[car][dictionary response]\n",
    "    extracted = {entry['BODY_DEF'].split('(')[0].strip(): entry['BODY_ID'] for entry in data['Results'][0]}\n",
    "\n",
    "    # append extracted to main list\n",
    "    bodytypes.append(extracted)\n",
    "\n",
    "    # sleep for polite scraping\n",
    "    time.sleep(.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e29bc1-0828-44c1-bf99-48bf60217e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(\"body-types.json\"):\n",
    "    with open(\"body-types.json\", \"w\") as outfile:\n",
    "        outfile.write(json.dumps(bodytypes))\n",
    "else:\n",
    "    with open('body-types.json', 'r') as openfile:\n",
    "        bodytypes = json.load(openfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707f1562-1f68-4f1b-adb9-2a24b83e7015",
   "metadata": {},
   "outputs": [],
   "source": [
    "BodyDef = []\n",
    "BodyId = []\n",
    "for dictionary in bodytypes:\n",
    "    for key, value in dictionary.items():\n",
    "        BodyDef.append(key)\n",
    "        BodyId.append(int(value))\n",
    "        break\n",
    "        \n",
    "df['BodyID'] = BodyId\n",
    "df['BodyType'] = BodyDef\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f5f2a2-b40f-4063-b6db-867cd518f633",
   "metadata": {},
   "source": [
    "## Getting Crashes Per Year Per Car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688dc966-5b02-4c3a-a2d1-bdb6a1f53ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to add crash totals per model to above dataframe \n",
    "# this will be done by simply tallying responses for each car\n",
    "# Since the api has a max return limit, querying by each year (2010-onwards) will ensure all data is gathered, and allow for year grouping\n",
    "\n",
    "# Base URL for NHTSA API\n",
    "base_url = \"https://crashviewer.nhtsa.dot.gov/CrashAPI/FARSData/GetFARSData\"\n",
    "\n",
    "# Function to get fatal crash data for a specific year and state\n",
    "def get_fatal_crashes(year, state):\n",
    "    params = f\"?dataset=Vehicle&FromYear={year}&ToYear={year}&state={state}&format=json\"\n",
    "    response = requests.get(base_url + params)\n",
    "\n",
    "    # Check for issues\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Error: Received status code {response.status_code}\")\n",
    "        print(f\"Response content: {response.text}\")\n",
    "        raise Exception(f\"API request failed with status code {response.status_code}\")\n",
    "\n",
    "    data = response.json()\n",
    "    if response[\"Message\"] == \"Results returned successfully\":\n",
    "        return data.get(\"Results\", [])\n",
    "    else:\n",
    "        print(f\"Error at api call for {year} and {state}!\")\n",
    "\n",
    "\n",
    "years = range(2010, 2010)\n",
    "states = range(1, 57)\n",
    "\n",
    "# Adding year columns to DataFrame for fatal crashes\n",
    "for year in years:\n",
    "    df[str(year)] = 0\n",
    "\n",
    "for year in tqdm.tqdm(years):\n",
    "    for state in states:\n",
    "        crash_data = get_fatal_crashes(year, state)\n",
    "        time.sleep(10)\n",
    "        \n",
    "        # Iterate over each vehicle in the crash data\n",
    "        for vehicle_list in crash_data:\n",
    "            for vehicle in vehicle_list:  # vehicle_list contains crash details for a particular vehicle\n",
    "                make = vehicle['MAKENAME']  # We are using 'MAKENAME' from the response\n",
    "                model = vehicle['MODELNAME']  # We are using 'MODELNAME' from the response\n",
    "                deaths = int(vehicle['DEATHS'])  # Convert deaths to an integer\n",
    "                \n",
    "                # Find the row in the dataframe that matches the make and model\n",
    "                vehicle_row = df[(df['MakeName'] == make) & (df['ModelName'] == model)]\n",
    "\n",
    "                # If the vehicle is found, update the deaths for that year\n",
    "                if not vehicle_row.empty:\n",
    "                    df.loc[vehicle_row.index, str(year)] += deaths\n",
    "\n",
    "        # Periodically save the dataframe after processing each state\n",
    "        df.to_csv(\"fatal_crashes.csv\", mode='w', header=True, index=False)\n",
    "\n",
    "# Check the updated DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be850427-118e-4c15-91fe-1fe14626fb83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d52573-2b2d-4f0b-83dc-a37d8ea495a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25172caa-31bf-4cdc-9a89-21a404ea25a0",
   "metadata": {},
   "source": [
    "## Transformation\n",
    "Now that we have usable, workable data, we can begin cleaning and organizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc56862a-5069-42b1-87fd-ae4dd22dea7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation code\n",
    "\n",
    "# Drop any unneeded columns/rows\n",
    "    # duplicates\n",
    "    # nulls\n",
    "    # outliers\n",
    "\n",
    "# Merge/Join Data into one dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0ba1ff-478a-4523-9053-dc63d992e3f9",
   "metadata": {},
   "source": [
    "## Load\n",
    "With curated data, can now be loaded into postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f00958-3245-43c7-b1cc-552c33bd200a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sql alchemy and stuff\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "with open('credentials.json', 'r') as openfile:\n",
    "    credentials = json.load(openfile)\n",
    "\n",
    "\n",
    "TABLE_NAME = 'car_data'\n",
    "\n",
    "DB_NAME = \"safecars\"\n",
    "DB_USER = credentials['user']\n",
    "DB_PASS = credentials['pass']\n",
    "DB_HOST = \"localhost\"\n",
    "DB_PORT = \"5432\"\n",
    "\n",
    "# create engine with defined macros\n",
    "engine = create_engine(f\"postgresql+psycopg2://{DB_USER}:{DB_PASS}@{DB_HOST}/{DB_NAME}\")\n",
    "# send the df over\n",
    "#df.to_sql(name=TABLE_NAME,\n",
    "          con=engine,\n",
    "          index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17e2a1b-7c46-4372-9b03-7cb4e2508b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"SELECT * FROM car_data\" # simple query for all rows\n",
    "#sql_df = pd.read_sql(sql, engine) # make a df from postgres\n",
    "#sql_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
